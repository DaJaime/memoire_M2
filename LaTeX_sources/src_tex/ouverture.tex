\chapter*{Ouverture}
%\addcontentsline{toc}{chapter}{Conclusion}
%\markboth{Conclusion}{Conclusion}
%\label{sec:conclusion}

En plus de résoudre les questions d'éthique, de fiabilité et de performance vue dans ce mémoire, l'interprétabilité et l'explicabilité des modèles prédictifs nous permettrai d'ouvrir de nouvelles portes. L'essor de l'intelligence artificielle et, en parallèle, son explication permet d'introduire un nouveau concept que j'ai appelé "L'intelligence artificielle comme compréhension du monde". L'idée est de détourner l'IA de sa fonction de prédiction de phénomènes pour lui donner une toute autre fonction qui serai la compréhension de phénomènes. Le principe est de prendre un phénomène que nous ne comprenons pas entièrement, de réussir à le prédire à l'aide d'un modèle, puis d'expliquer ce modèle avec les algorithmes d'interprétabilité afin de comprendre ce qui le pousse à donner ces prévisions et donc de mieux comprendre le phénomène de base.\par
Prenons un exemple trivial, imaginons que nous ne comprenons pas comment les éclairs se forment dans les nuages. Dans un premier temps, nous commencerons par récolter une multitude de données météorologiques et autre. Puis nous créons un modèle prenant ces données en entrée et capable de prédire la formation d'éclairs. La dernière étape consiste donc à expliquer notre modèle afin de comprendre quelles sont les facteurs entrent en jeu dans la formation des éclairs, ainsi que l'importance de ces facteurs (type de nuage, répartition des charges positives et négatives...).\par
Ce concept appliqué dans les domaines de l'infiniment petit ou de l'infiniment grand par exemple, pourrai nous aider à mieux comprendre certains phénomènes encore aujourd'hui non-expliqué.